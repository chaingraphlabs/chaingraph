# DBOS Durable Execution for Chaingraph

**Status**: âœ… Production Ready
**Version**: 2.0.0
**Last Updated**: 2025-10-09

## ğŸ“– Table of Contents

- [Overview](#overview)
- [Motivation](#motivation)
- [Architecture](#architecture)
- [Features](#features)
- [File Structure](#file-structure)
- [Configuration](#configuration)
- [Usage](#usage)
- [Child Executions](#child-executions)
- [Command System](#command-system)
- [Troubleshooting](#troubleshooting)
- [References](#references)

## ğŸ¯ Overview

This directory contains the **DBOS Durable Execution** implementation for the Chaingraph execution layer. It provides a PostgreSQL-native, durable execution engine that replaces Kafka for task distribution and event streaming while offering automatic recovery, exactly-once semantics, and real-time workflow control.

### What is DBOS?

DBOS (Database-Oriented Operating System) is a durable execution framework that uses PostgreSQL as its foundation for:
- **Workflow orchestration** - Multi-step durable workflows with automatic checkpointing
- **Queue management** - PostgreSQL-backed durable queues with concurrency control
- **Event streaming** - Real-time workflow streams stored in PostgreSQL
- **Messaging** - Durable inter-workflow communication
- **Recovery** - Automatic workflow recovery on failures

### Quick Start

```bash
# Enable DBOS mode
export ENABLE_DBOS_EXECUTION=true

# Start services
pnpm run dev
```

## ğŸ’¡ Motivation

### Problems with Kafka-Based Architecture

The original Kafka-based execution system had several challenges:

| Challenge | Impact | Lines of Code |
|-----------|--------|---------------|
| **Custom Recovery Logic** | Complex failure handling | ~350 lines |
| **Manual Claim Management** | Heartbeats, timeouts, expiration | ~200 lines |
| **Manual Offset Commits** | Race conditions, duplicates | ~150 lines |
| **At-Least-Once Semantics** | Possible duplicate executions | - |
| **Two Infrastructure Systems** | Kafka + PostgreSQL = operational overhead | - |
| **Event Streaming Race Conditions** | Clients subscribe before stream exists | - |

**Total complexity**: ~1,000+ lines of custom infrastructure code

### DBOS Benefits

| Benefit | Description | Code Saved |
|---------|-------------|------------|
| **Automatic Recovery** | Built-in workflow recovery | ~350 lines |
| **Exactly-Once Execution** | Idempotent workflows via workflow IDs | ~200 lines |
| **Durable Queues** | PostgreSQL-backed, no Kafka needed for tasks | ~150 lines |
| **Real-Time Streaming** | Built-in workflow streams | 0 (Kafka code reused) |
| **Workflow Messaging** | Inter-workflow communication for commands | New feature! |
| **Single Infrastructure** | PostgreSQL only (no Kafka for core execution) | Operational simplification |

**Total code reduction**: ~700 lines removed, ~500 lines added = **200 lines net reduction** with more features

### Design Philosophy

1. **PostgreSQL-Native** - Leverage PostgreSQL for all durable operations
2. **Automatic Everything** - Let DBOS handle recovery, retries, checkpointing
3. **Real-Time First** - Stream events and state changes immediately
4. **Developer Experience** - Simple API, clear error messages, easy debugging
5. **Production Ready** - Battle-tested DBOS runtime, proven scalability

## ğŸ—ï¸ Architecture

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT (tRPC)                                 â”‚
â”‚  1. create execution  â†’ Creates ExecutionRow in PostgreSQL      â”‚
â”‚                        â†’ Starts workflow immediately            â”‚
â”‚                        â†’ Workflow writes EXECUTION_CREATED      â”‚
â”‚                        â†’ Stream exists! âœ…                        â”‚
â”‚  2. subscribe events  â†’ Receives EXECUTION_CREATED immediately  â”‚
â”‚                        â†’ Subscription active âœ…                   â”‚
â”‚  3. start execution   â†’ Sends START_SIGNAL via DBOS.send()     â”‚
â”‚                        â†’ Workflow continues â–¶ï¸                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXECUTION WORKFLOW (DBOS Workflow)                  â”‚
â”‚                                                                  â”‚
â”‚  PHASE 1: Initialization (immediate)                            â”‚
â”‚    â”œâ”€ Create AbortController & CommandController               â”‚
â”‚    â”œâ”€ Start command polling (DBOS.recv every 500ms)             â”‚
â”‚    â”œâ”€ Load execution metadata from PostgreSQL                   â”‚
â”‚    â”œâ”€ DBOS.writeStream('events', EXECUTION_CREATED) âœ…           â”‚
â”‚    â”œâ”€ Auto-start check (child? send signal to self)             â”‚
â”‚    â””â”€ DBOS.recv('START_SIGNAL', timeout) â¸ï¸                      â”‚
â”‚                                                                  â”‚
â”‚  PHASE 2: Execution (after START_SIGNAL)                        â”‚
â”‚    â”œâ”€ Step 1: updateToRunning() âœ“ checkpoint                   â”‚
â”‚    â”œâ”€ Step 2: executeFlowAtomic() âœ“ checkpoint                 â”‚
â”‚    â”‚   â”œâ”€ Load flow from PostgreSQL                             â”‚
â”‚    â”‚   â”œâ”€ Create execution instance                             â”‚
â”‚    â”‚   â”œâ”€ Execute flow (with command checking every 100ms)      â”‚
â”‚    â”‚   â”œâ”€ Stream events via DBOS.writeStream() in real-time     â”‚
â”‚    â”‚   â”œâ”€ Collect child tasks from emitted events               â”‚
â”‚    â”‚   â””â”€ Return { status, duration, childTasks }               â”‚
â”‚    â”œâ”€ Spawn children (DBOS.startWorkflow for each) âœ“            â”‚
â”‚    â””â”€ Step 3: updateToCompleted() âœ“ checkpoint                 â”‚
â”‚                                                                  â”‚
â”‚  PHASE 3: Cleanup (automatic)                                   â”‚
â”‚    â”œâ”€ Stop command polling                                      â”‚
â”‚    â””â”€ DBOS auto-closes event stream âœ…                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CHILD EXECUTIONS (Recursive)                     â”‚
â”‚  Each child follows the same workflow pattern:                  â”‚
â”‚    â”œâ”€ Writes own EXECUTION_CREATED event                        â”‚
â”‚    â”œâ”€ Auto-starts (no manual START_SIGNAL needed) ğŸš€             â”‚
â”‚    â”œâ”€ Executes flow                                             â”‚
â”‚    â”œâ”€ Can spawn its own children (up to depth 100)              â”‚
â”‚    â””â”€ Completes independently                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: tRPC API (server/trpc/router.ts)                   â”‚
â”‚  â”œâ”€ create()  â†’ Start workflow, return executionId           â”‚
â”‚  â”œâ”€ start()   â†’ Send START_SIGNAL                            â”‚
â”‚  â”œâ”€ stop()    â†’ DBOS.cancelWorkflow() (immediate)            â”‚
â”‚  â”œâ”€ pause()   â†’ DBOS.send('COMMAND', {command: 'PAUSE'})     â”‚
â”‚  â””â”€ resume()  â†’ DBOS.send('COMMAND', {command: 'RESUME'})    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Workflows (workflows/ExecutionWorkflow.ts)          â”‚
â”‚  â”œâ”€ Signal Pattern (START_SIGNAL wait)                       â”‚
â”‚  â”œâ”€ Command Polling (DBOS.recv every 500ms)                  â”‚
â”‚  â”œâ”€ Stream Initialization (EXECUTION_CREATED)                â”‚
â”‚  â”œâ”€ Step Orchestration (3 durable checkpoints)               â”‚
â”‚  â””â”€ Child Spawning (DBOS.startWorkflow after step)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Steps (steps/*.ts)                                  â”‚
â”‚  â”œâ”€ UpdateStatusStep.ts                                      â”‚
â”‚  â”‚   â”œâ”€ updateToRunning()                                    â”‚
â”‚  â”‚   â”œâ”€ updateToCompleted()                                  â”‚
â”‚  â”‚   â””â”€ updateToFailed()                                     â”‚
â”‚  â””â”€ ExecuteFlowAtomicStep.ts (THE CORE STEP)                 â”‚
â”‚      â”œâ”€ Load flow from PostgreSQL                            â”‚
â”‚      â”œâ”€ Create execution instance with controllers           â”‚
â”‚      â”œâ”€ Execute flow (up to 30 minutes)                      â”‚
â”‚      â”œâ”€ Stream events via DBOS.writeStream()                 â”‚
â”‚      â”œâ”€ Check commands every 100ms (shared state)            â”‚
â”‚      â”œâ”€ Collect child tasks from emitted events              â”‚
â”‚      â””â”€ Return result with childTasks                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Services (server/services/)                         â”‚
â”‚  â”œâ”€ ExecutionService.ts                                      â”‚
â”‚  â”‚   â”œâ”€ createExecutionInstance()                            â”‚
â”‚  â”‚   â”œâ”€ setupEventHandling() (DBOS streams)                  â”‚
â”‚  â”‚   â””â”€ getEventBus()                                        â”‚
â”‚  â””â”€ ServiceFactory.ts                                        â”‚
â”‚      â”œâ”€ Initializes DBOS runtime                             â”‚
â”‚      â”œâ”€ Creates DBOSEventBus                                 â”‚
â”‚      â”œâ”€ Creates DBOSTaskQueue                                â”‚
â”‚      â””â”€ Starts workers                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: Infrastructure                                      â”‚
â”‚  â”œâ”€ PostgreSQL (DBOS system tables + execution data)         â”‚
â”‚  â””â”€ DBOS Runtime (workflow engine, queues, streams)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### 1. Real-Time Event Streaming

**File**: [`server/implementations/dbos/DBOSEventBus.ts`](../implementations/dbos/DBOSEventBus.ts)

Events are streamed in real-time via `DBOS.writeStream()` as the flow executes:

```typescript
// Published from step (allowed!)
await DBOS.writeStream('events', {
  executionId,
  event: serializedEvent,
  timestamp: Date.now(),
})

// Consumed from anywhere
for await (const streamValue of DBOS.readStream(executionId, 'events')) {
  const event = ExecutionEventImpl.deserializeStatic(streamValue.event)
  console.log(`[${event.index}] ${event.type}`, event.data)
}
```

**Key Points**:
- Events written from **step** = at-least-once semantics (may duplicate on retry)
- Events written from **workflow** = exactly-once semantics
- Stream auto-closes when workflow terminates
- No Kafka dependency for events (pure PostgreSQL)

**Documentation**: [DBOS_STREAMING_IMPLEMENTATION.md](../../DBOS_STREAMING_IMPLEMENTATION.md)

### 2. Signal Pattern (Race Condition Fix)

**File**: [`workflows/ExecutionWorkflow.ts`](./workflows/ExecutionWorkflow.ts)

Solves the race condition where clients subscribe to events before the stream exists:

```
Timeline:
1. create execution (tRPC)
   â””â”€ Workflow starts â†’ writes EXECUTION_CREATED (index -1) â†’ stream exists! âœ…
   â””â”€ Workflow waits for START_SIGNAL... â¸ï¸

2. subscribe events (tRPC)
   â””â”€ Stream already exists â†’ immediately receives EXECUTION_CREATED âœ…

3. start execution (tRPC)
   â””â”€ Sends START_SIGNAL â†’ workflow continues â–¶ï¸
```

**Benefits**:
- âœ… Stream guaranteed to exist before subscribe
- âœ… No missed events
- âœ… Rich metadata in EXECUTION_CREATED event (ownerId, rootExecutionId, depth, etc.)
- âœ… Timeout protection (5 minutes for parents, auto-start for children)

### 3. Hybrid Command System

**Files**:
- tRPC: [`server/trpc/router.ts`](../../trpc/router.ts)
- Workflow: [`workflows/ExecutionWorkflow.ts`](./workflows/ExecutionWorkflow.ts)
- Step: [`steps/ExecuteFlowAtomicStep.ts`](./steps/ExecuteFlowAtomicStep.ts)

Commands for controlling execution during runtime:

| Command | Mechanism | Where | Latency |
|---------|-----------|-------|---------|
| **STOP** | `DBOS.cancelWorkflow()` | Workflow cancellation | Immediate |
| **PAUSE** | `DBOS.send()` + polling | Workflow â†’ shared state | ~600ms |
| **RESUME** | `DBOS.send()` + polling | Workflow â†’ shared state | ~600ms |
| **STEP** | `DBOS.send()` + polling | Workflow â†’ shared state | ~600ms |

**Architecture**:
```
Workflow Level (ExecutionWorkflow.ts):
  â”œâ”€ Create AbortController (for STOP)
  â”œâ”€ Create CommandController (for PAUSE/RESUME/STEP)
  â”œâ”€ Poll DBOS.recv('COMMAND') every 500ms
  â”‚   â””â”€ STOP â†’ abortController.abort()
  â”‚   â””â”€ PAUSE/RESUME/STEP â†’ commandController.currentCommand = cmd
  â””â”€ Pass controllers to step â¬‡ï¸

Step Level (ExecuteFlowAtomicStep.ts):
  â”œâ”€ Check commandController every 100ms
  â”‚   â””â”€ PAUSE â†’ debugger.pause()
  â”‚   â””â”€ RESUME â†’ debugger.continue()
  â”‚   â””â”€ STEP â†’ debugger.step()
  â””â”€ Engine monitors abortController.signal
```

**Why Hybrid?**
- `DBOS.recv()` can **only** be called from workflows (not steps)
- Solution: Workflow polls messages, updates shared state
- Step reads shared state (no DBOS calls needed)

**Documentation**: [DBOS_COMMAND_SYSTEM.md](../../DBOS_COMMAND_SYSTEM.md)

### 4. Child Execution Support (Event Emitter Nodes)

**Files**:
- Step: [`steps/ExecuteFlowAtomicStep.ts`](./steps/ExecuteFlowAtomicStep.ts)
- Workflow: [`workflows/ExecutionWorkflow.ts`](./workflows/ExecutionWorkflow.ts)

Supports parent-child execution trees via Event Emitter nodes:

```
Parent Execution:
  â”œâ”€ EventEmitter node executes
  â”œâ”€ context.emitEvent('event-name', data)
  â”œâ”€ Event stored in context.emittedEvents[]
  â”œâ”€ Step completes, returns { childTasks: [...] }
  â”‚
  â””â”€ Workflow spawns children (allowed at workflow level!):
      For each childTask:
        â””â”€ DBOS.startWorkflow(executionWorkflow, {
             workflowID: childTask.executionId
           })(childTask)

Child Execution:
  â”œâ”€ Workflow starts â†’ writes EXECUTION_CREATED
  â”œâ”€ Detects parentExecutionId â†’ auto-starts (sends signal to self) ğŸš€
  â”œâ”€ Executes flow independently
  â”œâ”€ Can spawn its own children (up to depth 100)
  â””â”€ Completes independently
```

**Why Collect & Spawn?**
- `DBOS.startWorkflow()` can **only** be called from workflows (not steps)
- Solution: Collect child tasks in step, spawn from workflow
- Fast: ~15-30ms per child, non-blocking for parent

**Key Constraint**:
```
âŒ DBOS.send()          - Not allowed in steps
âŒ DBOS.recv()          - Not allowed in steps
âŒ DBOS.startWorkflow() - Not allowed in steps
âŒ DBOS.setEvent()      - Not allowed in steps
âŒ DBOS.sleep()         - Not allowed in steps
âœ… DBOS.writeStream()   - Allowed in steps!
```

### 5. Auto-Start for Children

**File**: [`workflows/ExecutionWorkflow.ts:192-218`](./workflows/ExecutionWorkflow.ts)

Child executions auto-start without manual `start` call:

```typescript
const isChildExecution = !!executionRow.parentExecutionId

if (isChildExecution) {
  // Send START_SIGNAL to self
  await DBOS.send(task.executionId, 'AUTO-START', 'START_SIGNAL')
}

// Wait for signal (10s for children, 5min for parents)
const startSignal = await DBOS.recv<string>('START_SIGNAL', isChildExecution ? 10 : 300)
```

**Benefits**:
- Children execute immediately after spawning
- No manual intervention needed
- Parent can spawn hundreds of children without blocking
- Each child has independent lifecycle

## ğŸ“ File Structure

```
server/dbos/
â”œâ”€â”€ README.md                          # This file
â”‚
â”œâ”€â”€ config.ts                          # DBOS initialization & lifecycle
â”‚   â”œâ”€ initializeDBOS()                - Configure & launch DBOS
â”‚   â”œâ”€ shutdownDBOS()                  - Graceful shutdown
â”‚   â””â”€ isDBOSLaunched()                - Check initialization status
â”‚
â”œâ”€â”€ types.ts                           # TypeScript type definitions
â”‚   â”œâ”€ ExecutionResult                 - Workflow result (with childTasks)
â”‚   â”œâ”€ DBOSQueueOptions                - Queue configuration
â”‚   â””â”€ CommandController               - Shared command state
â”‚
â”œâ”€â”€ DBOSExecutionWorker.ts             # Main worker class
â”‚   â”œâ”€ start()                         - Initialize & start worker
â”‚   â”œâ”€ stop()                          - Graceful shutdown
â”‚   â””â”€ getQueue()                      - Access execution queue
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ ExecutionWorkflow.ts           # Main execution workflow â­
â”‚   â”‚   â”œâ”€ Phase 1: Stream initialization & signal wait
â”‚   â”‚   â”œâ”€ Phase 2: 3-step execution (running â†’ execute â†’ completed)
â”‚   â”‚   â”œâ”€ Command polling (DBOS.recv every 500ms)
â”‚   â”‚   â”œâ”€ Child spawning (DBOS.startWorkflow after step)
â”‚   â”‚   â””â”€ Auto-start logic for children
â”‚   â”‚
â”‚   â””â”€â”€ index.ts                       # Workflow exports
â”‚
â”œâ”€â”€ steps/
â”‚   â”œâ”€â”€ ExecuteFlowAtomicStep.ts       # THE CORE STEP â­â­â­
â”‚   â”‚   â”œâ”€ executeFlowAtomic()         - Main execution function
â”‚   â”‚   â”œâ”€ createChildTask()           - Helper for child spawning
â”‚   â”‚   â”œâ”€ Command checking (100ms interval)
â”‚   â”‚   â”œâ”€ Event streaming (DBOS.writeStream)
â”‚   â”‚   â””â”€ Child task collection
â”‚   â”‚
â”‚   â”œâ”€â”€ UpdateStatusStep.ts            # Status update steps
â”‚   â”‚   â”œâ”€ updateToRunning()
â”‚   â”‚   â”œâ”€ updateToCompleted()
â”‚   â”‚   â””â”€ updateToFailed()
â”‚   â”‚
â”‚   â””â”€â”€ index.ts                       # Step exports
â”‚
â”œâ”€â”€ queues/
â”‚   â”œâ”€â”€ ExecutionQueue.ts              # DBOS queue wrapper
â”‚   â”‚   â”œâ”€ enqueue()                   - Add task to queue
â”‚   â”‚   â”œâ”€ getWorkflowHandle()         - Get workflow handle
â”‚   â”‚   â”œâ”€ getStatus()                 - Query workflow status
â”‚   â”‚   â””â”€ getResult()                 - Wait for & get result
â”‚   â”‚
â”‚   â””â”€â”€ index.ts                       # Queue exports
â”‚
â””â”€â”€ index.ts                           # Main exports
```

### Integration Points

```
server/implementations/dbos/
â”œâ”€â”€ DBOSEventBus.ts                    # IEventBus implementation
â”‚   â”œâ”€ publishEvent()                  - Write to DBOS stream
â”‚   â””â”€ subscribeToEvents()             - Read from DBOS stream
â”‚
â””â”€â”€ DBOSTaskQueue.ts                   # ITaskQueue implementation
    â”œâ”€ publishTask()                   - Enqueue to DBOS queue
    â””â”€ consumeTasks()                  - No-op (DBOS auto-consumes)
```

### Service Layer

```
server/services/
â”œâ”€â”€ ServiceFactory.ts                  # Service initialization â­
â”‚   â”œâ”€ Creates DBOSEventBus
â”‚   â”œâ”€ Creates DBOSTaskQueue
â”‚   â”œâ”€ Creates ExecutionService
â”‚   â”œâ”€ Initializes steps
â”‚   â””â”€ Starts DBOS worker
â”‚
â””â”€â”€ ExecutionService.ts                # Execution logic
    â”œâ”€ createExecutionInstance()       - Setup flow engine
    â”œâ”€ setupEventHandling()            - Subscribe to engine events
    â””â”€ getEventBus()                   - Access event bus
```

## âš™ï¸ Configuration

### Environment Variables

```bash
# ============================================================
# DBOS Configuration
# ============================================================

# Enable DBOS mode (default: false)
ENABLE_DBOS_EXECUTION=true

# DBOS Conductor (optional, for production monitoring)
# DBOS_CONDUCTOR_URL=https://conductor.dbos.dev
DBOS_APPLICATION_NAME=chaingraph-executor
# DBOS_CONDUCTOR_KEY=your-api-key-here

# DBOS Admin Server (local management UI)
DBOS_ADMIN_ENABLED=true
DBOS_ADMIN_PORT=3022                  # Default: 3022

# Concurrency Limits
DBOS_QUEUE_CONCURRENCY=100            # Global across all workers
DBOS_WORKER_CONCURRENCY=5              # Per worker process

# ============================================================
# Legacy Configuration (still needed for execution data)
# ============================================================

# Execution data storage
DATABASE_URL_EXECUTIONS=postgres://postgres@localhost:5432/chaingraph

# Execution mode
EXECUTION_MODE=distributed             # or 'local'
```

### Configuration File

**File**: [`server/utils/config.ts`](../../utils/config.ts)

```typescript
export const config = {
  dbos: {
    enabled: process.env.ENABLE_DBOS_EXECUTION === 'true',
    systemDatabaseUrl: process.env.DATABASE_URL_EXECUTIONS || ...,
    conductorURL: process.env.DBOS_CONDUCTOR_URL,
    applicationName: process.env.DBOS_APPLICATION_NAME || 'chaingraph-executor',
    conductorKey: process.env.DBOS_CONDUCTOR_KEY,
    adminServer: {
      enabled: process.env.DBOS_ADMIN_ENABLED !== 'false',
      port: Number.parseInt(process.env.DBOS_ADMIN_PORT) || 3022,
    },
    queueConcurrency: Number.parseInt(process.env.DBOS_QUEUE_CONCURRENCY) || 100,
    workerConcurrency: Number.parseInt(process.env.DBOS_WORKER_CONCURRENCY) || 5,
  },
}
```

## ğŸš€ Usage

### Initialize DBOS

**File**: [`config.ts`](./config.ts)

```typescript
import { initializeDBOS, shutdownDBOS } from '@badaitech/chaingraph-executor/server'

// Initialize DBOS runtime
await initializeDBOS()

// ... application runs ...

// Graceful shutdown
await shutdownDBOS()
```

### Start Worker

**File**: [`DBOSExecutionWorker.ts`](./DBOSExecutionWorker.ts)

```typescript
import { DBOSExecutionWorker } from '@badaitech/chaingraph-executor/server'

const worker = new DBOSExecutionWorker(
  executionStore,
  executionService,
  {
    concurrency: 100,
    workerConcurrency: 5,
  }
)

await worker.start()
// Worker now processes queued executions automatically
```

### Enqueue Execution

**File**: [`server/trpc/router.ts:128-239`](../../trpc/router.ts)

```typescript
// Create execution (starts workflow, stream initialized)
const { executionId } = await trpc.execution.create.mutate({
  flowId: 'V2ENKK6...',
  options: {},
  integration: { archai: { agentID, chatID } },
})

// Subscribe to events (stream exists, receives EXECUTION_CREATED)
const subscription = trpc.execution.subscribeToExecutionEvents.subscribe({
  executionId,
  fromIndex: 0,
})

// Start execution (sends START_SIGNAL)
await trpc.execution.start.mutate({ executionId })
```

### Control Execution

```typescript
// Pause (debugger stops at next node)
await trpc.execution.pause.mutate({
  executionId,
  reason: 'Debugging',
})

// Resume (debugger continues)
await trpc.execution.resume.mutate({ executionId })

// Stop (immediate cancellation)
await trpc.execution.stop.mutate({
  executionId,
  reason: 'User cancelled',
})
```

### Query Workflow Status

```typescript
import { DBOS } from '@dbos-inc/dbos-sdk'

// Get workflow status
const status = await DBOS.getStatus(executionId)
console.log(status.status) // PENDING, SUCCESS, ERROR, CANCELLED

// List workflows
const workflows = await DBOS.listWorkflows({
  workflowName: 'executeChainGraph',
  status: 'PENDING',
  limit: 50,
})

// Get workflow steps
const steps = await DBOS.listWorkflowSteps(executionId)
console.log(steps) // [updateToRunning, executeFlowAtomic, updateToCompleted]
```

## ğŸ‘¶ Child Executions

### Event Emitter Flow

**Node**: `@badaitech/chaingraph-nodes/src/nodes/flow/emitter.node.ts`

```typescript
// EventEmitter node executes
context.emitEvent('user-created', { userId: 123, name: 'Alice' })

// â†“ Event stored in context.emittedEvents[]

// â†“ After node completes, step collects event

// â†“ Step creates child ExecutionRow in DB

// â†“ Step returns { childTasks: [childTask] }

// â†“ Workflow spawns child via DBOS.startWorkflow()

// â†“ Child workflow starts:
//   - Writes own EXECUTION_CREATED event
//   - Auto-starts (sends START_SIGNAL to self)
//   - Executes flow
//   - Can spawn grandchildren (up to depth 100)
```

### Child Execution Lifecycle

```typescript
// Parent
const parentId = 'EXparent123'

// Parent emits event
// EventEmitter node â†’ context.emitEvent('user-action', data)

// Child auto-spawned
const childId = 'EXchild456'
// â”œâ”€ parentExecutionId = 'EXparent123'
// â”œâ”€ rootExecutionId = 'EXparent123' (or parent's root)
// â”œâ”€ executionDepth = parent.depth + 1
// â”œâ”€ Auto-starts immediately
// â””â”€ Executes independently

// Child can spawn grandchildren
// Grandchild:
// â”œâ”€ parentExecutionId = 'EXchild456'
// â”œâ”€ rootExecutionId = 'EXparent123'
// â”œâ”€ executionDepth = parent.depth + 2
// â””â”€ And so on... (up to depth 100)
```

### Collect & Spawn Pattern

**Why this pattern?**
```
âŒ Cannot call DBOS.startWorkflow() from step
âŒ Cannot call DBOS.send() from step
âœ… Can return data from step to workflow
âœ… Can call DBOS.startWorkflow() from workflow
```

**Implementation**:
```typescript
// Step (ExecuteFlowAtomicStep.ts:231-258)
for (const event of context.emittedEvents.filter(e => !e.processed)) {
  const childTask = await createChildTask(instance, event, store)
  collectedChildTasks.push(childTask)
}
return { childTasks: collectedChildTasks }

// Workflow (ExecutionWorkflow.ts:236-258)
if (result.childTasks && result.childTasks.length > 0) {
  for (const childTask of result.childTasks) {
    await DBOS.startWorkflow(executionWorkflow, {
      workflowID: childTask.executionId
    })(childTask)
  }
}
```

## ğŸ® Command System

### Command Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  tRPC API Layer                                           â”‚
â”‚  â”œâ”€ stop   â†’ DBOS.cancelWorkflow(executionId)            â”‚
â”‚  â”œâ”€ pause  â†’ DBOS.send(executionId, {cmd: 'PAUSE'})      â”‚
â”‚  â”œâ”€ resume â†’ DBOS.send(executionId, {cmd: 'RESUME'})     â”‚
â”‚  â””â”€ step   â†’ DBOS.send(executionId, {cmd: 'STEP'})       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Workflow Level (ExecutionWorkflow.ts)                   â”‚
â”‚  Command Polling Loop (500ms):                           â”‚
â”‚    const cmd = await DBOS.recv('COMMAND', 0)             â”‚
â”‚    if (cmd.command === 'STOP'):                          â”‚
â”‚      abortController.abort()                             â”‚
â”‚    else:                                                 â”‚
â”‚      commandController.currentCommand = cmd.command      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step Level (ExecuteFlowAtomicStep.ts)                   â”‚
â”‚  Command Checking Loop (100ms):                          â”‚
â”‚    if (commandController.currentCommand):                â”‚
â”‚      switch (commandController.currentCommand):          â”‚
â”‚        PAUSE  â†’ debugger.pause()                         â”‚
â”‚        RESUME â†’ debugger.continue()                      â”‚
â”‚        STEP   â†’ debugger.step()                          â”‚
â”‚    if (abortController.signal.aborted):                  â”‚
â”‚      â†’ Engine stops gracefully                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Two-Level Polling?

**Workflow Level (500ms)**:
- Receives DBOS messages
- Updates shared state
- Handles STOP via abort()

**Step Level (100ms)**:
- Checks shared state (no DBOS calls!)
- Faster responsiveness
- No DBOS constraints violated

**Total Latency**: ~600ms from tRPC call to command execution

## ğŸ”§ Troubleshooting

### Issue: Events Not Streaming

**Symptoms**: Execution completes but client receives no events

**Check**:
```typescript
// 1. Verify DBOS mode is enabled
console.log(config.dbos.enabled) // Should be true

// 2. Verify event bus is DBOSEventBus
const eventBus = getServices()?.eventBus
console.log(eventBus instanceof DBOSEventBus) // Should be true

// 3. Check DBOS stream
const events = []
for await (const value of DBOS.readStream(executionId, 'events')) {
  events.push(value)
}
console.log(events) // Should have EXECUTION_CREATED + flow events
```

**Solution**: Ensure `ENABLE_DBOS_EXECUTION=true` in environment

### Issue: Child Executions Not Starting

**Symptoms**: Child created in DB but never executes

**Check**:
```sql
-- Check child execution status
SELECT id, parent_execution_id, status, created_at
FROM executions
WHERE parent_execution_id = 'EXparent123';

-- Should see status = 'created' then 'running' then 'completed'
```

**Debug**:
```typescript
// Check if auto-start happened
// Look for log: "Auto-starting child execution: EXchild456"

// Check if START_SIGNAL received
// Look for log: "START_SIGNAL received, beginning execution"
```

**Solution**: Verify `ExecutionWorkflow.ts:192-218` has auto-start logic

### Issue: Commands Not Working

**Symptoms**: pause/resume/stop calls succeed but execution doesn't respond

**Check**:
```typescript
// 1. Verify command polling is running
// Look for log: "Received command: PAUSE for EX123..."

// 2. Check shared state updates
// CommandController should be updated by workflow polling

// 3. Verify step command checking
// Look for log: "Processing command: PAUSE for EX123..."
```

**Debug**:
```bash
# Enable debug logging
export LOG_LEVEL=debug

# Watch for command flow
tail -f logs/worker.log | grep -i "command"
```

**Solution**: Ensure both workflow polling (500ms) and step checking (100ms) are running

### Issue: Workflow Timeout

**Symptoms**: "Execution start timeout - START_SIGNAL not received"

**Cause**: Parent execution created but `start` never called

**Solution**:
```typescript
// Must call start after create
const { executionId } = await trpc.execution.create.mutate({ flowId })
await trpc.execution.start.mutate({ executionId }) // â† Required!
```

**Children**: Auto-start, no manual start needed

### Issue: DBOS Constraint Violations

**Symptoms**: "Invalid call to X inside a step or transaction"

**Common Violations**:
```typescript
// âŒ From step
await DBOS.send(...)          // Not allowed
await DBOS.recv(...)          // Not allowed
await DBOS.startWorkflow(...) // Not allowed
await DBOS.setEvent(...)      // Not allowed
await DBOS.sleep(...)         // Not allowed

// âœ… From step
await DBOS.writeStream(...)   // Allowed!
```

**Solution**: Move DBOS context methods to workflow level, use shared state in steps

## ğŸ“š References

### Documentation

- **Streaming**: [DBOS_STREAMING_IMPLEMENTATION.md](../../DBOS_STREAMING_IMPLEMENTATION.md)
- **Commands**: [DBOS_COMMAND_SYSTEM.md](../../DBOS_COMMAND_SYSTEM.md)
- **Architecture**: [ARCHITECTURE.md](../../ARCHITECTURE.md)
- **Changelog**: [CHANGELOG.md](../../CHANGELOG.md)

### External Resources

- [DBOS Documentation](https://docs.dbos.dev/)
- [DBOS TypeScript Guide](https://docs.dbos.dev/typescript/programming-guide)
- [DBOS Workflow Tutorial](https://docs.dbos.dev/typescript/tutorials/workflow-tutorial)
- [DBOS Queue Tutorial](https://docs.dbos.dev/typescript/tutorials/queue-tutorial)
- [DBOS Streaming](https://docs.dbos.dev/typescript/tutorials/workflow-communication#workflow-streaming)
- [DBOS Messaging](https://docs.dbos.dev/typescript/tutorials/workflow-communication#workflow-messaging-and-notifications)
- [DBOS GitHub](https://github.com/dbos-inc/dbos-transact-ts)

### Key Files Reference

| File | Purpose | Lines | Critical? |
|------|---------|-------|-----------|
| [`workflows/ExecutionWorkflow.ts`](./workflows/ExecutionWorkflow.ts) | Main orchestration workflow | ~280 | â­â­â­ |
| [`steps/ExecuteFlowAtomicStep.ts`](./steps/ExecuteFlowAtomicStep.ts) | Core execution step | ~350 | â­â­â­ |
| [`config.ts`](./config.ts) | DBOS initialization | ~95 | â­â­ |
| [`DBOSExecutionWorker.ts`](./DBOSExecutionWorker.ts) | Worker lifecycle | ~180 | â­â­ |
| [`queues/ExecutionQueue.ts`](./queues/ExecutionQueue.ts) | Queue wrapper | ~120 | â­ |
| [`steps/UpdateStatusStep.ts`](./steps/UpdateStatusStep.ts) | Status updates | ~92 | â­ |
| [`../implementations/dbos/DBOSEventBus.ts`](../implementations/dbos/DBOSEventBus.ts) | Event streaming | ~250 | â­â­ |
| [`../implementations/dbos/DBOSTaskQueue.ts`](../implementations/dbos/DBOSTaskQueue.ts) | Task queueing | ~120 | â­ |

## ğŸ¯ Design Patterns

### 1. Signal Pattern
**Problem**: Stream doesn't exist when client subscribes
**Solution**: Workflow writes initialization event before waiting for start signal
**File**: `workflows/ExecutionWorkflow.ts:148-218`

### 2. Shared State Pattern
**Problem**: Cannot call DBOS.recv() from steps
**Solution**: Workflow polls, updates shared CommandController object
**File**: `workflows/ExecutionWorkflow.ts:107-146`

### 3. Collect & Spawn Pattern
**Problem**: Cannot call DBOS.startWorkflow() from steps
**Solution**: Step collects child tasks, workflow spawns them
**File**: `steps/ExecuteFlowAtomicStep.ts:231-258` + `workflows/ExecutionWorkflow.ts:236-258`

### 4. Auto-Start Pattern
**Problem**: Children need manual start call
**Solution**: Children send START_SIGNAL to themselves
**File**: `workflows/ExecutionWorkflow.ts:192-218`

## ğŸ† Success Metrics

### Performance

- **Execution Latency**: ~50-150ms overhead vs Kafka (acceptable)
- **Event Streaming**: Real-time, <10ms per event
- **Child Spawning**: ~15-30ms per child, non-blocking
- **Command Latency**: ~600ms (workflow poll + step check)

### Reliability

- **Exactly-Once Execution**: âœ… Via workflow IDs
- **Automatic Recovery**: âœ… Via DBOS checkpoints
- **Event Durability**: âœ… Via DBOS streams (PostgreSQL)
- **Message Delivery**: âœ… Guaranteed via DBOS.send()

### Operational

- **Infrastructure**: PostgreSQL only (simpler)
- **Code Complexity**: -200 lines net (1,000 removed, 800 added)
- **Monitoring**: DBOS Admin UI + Conductor (optional)
- **Debugging**: Query workflows as database rows

## ğŸ¤ Contributing

When modifying the DBOS implementation:

### Guidelines

1. **DBOS Constraints**: Know what's allowed where
   - Workflow: All DBOS methods âœ…
   - Step: Only DBOS.writeStream() âœ…

2. **Atomic Execution**: Keep executeFlowAtomic as ONE step
   - Don't split into multiple steps
   - Flow state must stay in-memory

3. **Real-Time Streaming**: Events must stream during execution
   - Don't batch events for later
   - Use DBOS.writeStream() from step

4. **Graceful Degradation**: Support Kafka mode fallback
   - Check `config.dbos.enabled` before DBOS-specific code
   - Keep interface-based design

5. **Type Safety**: Fully typed, no `any`
   - Use proper TypeScript interfaces
   - Type all DBOS callbacks

### Testing Checklist

Before committing changes:

- [ ] TypeScript compiles: `pnpm typecheck`
- [ ] Parent execution works end-to-end
- [ ] Child executions spawn and execute
- [ ] Event streaming works (check DBOS.readStream)
- [ ] Commands work (pause/resume/stop)
- [ ] Workflow recovery works (simulate crash)
- [ ] Concurrency limits respected
- [ ] Kafka fallback mode still works

### Common Pitfalls

âŒ **Calling DBOS context methods from steps**
```typescript
// DON'T
async function myStep() {
  await DBOS.send(...) // âŒ Error!
}
```

âŒ **Splitting atomic step**
```typescript
// DON'T
await DBOS.runStep(() => loadFlow())
await DBOS.runStep(() => executeFlow()) // âŒ State lost!
```

âŒ **Forgetting auto-start for children**
```typescript
// DON'T
if (isChildExecution) {
  // Waiting... (times out after 10s)
}
```

âœ… **Correct Patterns**
```typescript
// DO: Collect in step, spawn in workflow
const result = await DBOS.runStep(() => executeFlowAtomic())
for (const child of result.childTasks) {
  await DBOS.startWorkflow(...)(child)
}

// DO: Workflow polls, step checks shared state
// Workflow:
const cmd = await DBOS.recv('COMMAND', 0)
commandController.currentCommand = cmd.command

// Step:
if (commandController.currentCommand) {
  // Process command
}
```

## ğŸ“Š Monitoring & Observability

### DBOS Admin UI

**Access**: `http://localhost:3022` (when `DBOS_ADMIN_ENABLED=true`)

**Features**:
- View all workflows (status, duration, progress)
- Inspect workflow steps
- View workflow inputs/outputs
- Cancel/resume workflows
- View system metrics

### DBOS Conductor (Optional)

**Purpose**: Production monitoring and management

**Features**:
- Multi-instance workflow recovery
- Cross-region observability
- Workflow management dashboard
- Alerts and notifications

**Setup**:
```bash
DBOS_CONDUCTOR_URL=https://conductor.dbos.dev
DBOS_APPLICATION_NAME=chaingraph-executor-prod
DBOS_CONDUCTOR_KEY=your-api-key
```

### SQL Queries

```sql
-- Active executions
SELECT workflow_uuid, status, created_at, updated_at
FROM dbos.workflow_status
WHERE status IN ('PENDING', 'ENQUEUED')
ORDER BY created_at DESC;

-- Failed executions
SELECT workflow_uuid, status, error, created_at
FROM dbos.workflow_status
WHERE status = 'ERROR'
ORDER BY created_at DESC
LIMIT 20;

-- Execution steps
SELECT workflow_uuid, function_id, name, status, output
FROM dbos.workflow_inputs
WHERE workflow_uuid = 'EX123...';

-- Queue depth
SELECT COUNT(*) as pending_count
FROM dbos.workflow_status
WHERE status = 'ENQUEUED' AND queue_name = 'chaingraph-executions';
```

## ğŸ“ Learning Resources

### Understanding DBOS Constraints

The most important concept is **where DBOS context methods can be called**:

```typescript
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DBOS Context Methods (DBOS.* functions)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… From WORKFLOW functions:                         â”‚
â”‚    - DBOS.send()                                    â”‚
â”‚    - DBOS.recv()                                    â”‚
â”‚    - DBOS.startWorkflow()                           â”‚
â”‚    - DBOS.setEvent() / getEvent()                   â”‚
â”‚    - DBOS.sleep()                                   â”‚
â”‚    - DBOS.cancelWorkflow()                          â”‚
â”‚    - DBOS.writeStream() / readStream()              â”‚
â”‚                                                     â”‚
â”‚  âœ… From STEP functions:                             â”‚
â”‚    - DBOS.writeStream()  (ONLY THIS ONE!)           â”‚
â”‚                                                     â”‚
â”‚  âŒ From STEP functions (NOT ALLOWED):               â”‚
â”‚    - DBOS.send()          â†’ Use shared state        â”‚
â”‚    - DBOS.recv()          â†’ Workflow level only     â”‚
â”‚    - DBOS.startWorkflow() â†’ Return data, spawn from workflow â”‚
â”‚    - DBOS.setEvent()      â†’ Workflow level only     â”‚
â”‚    - DBOS.sleep()         â†’ Use setTimeout instead  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Workflow

```typescript
// workflows/ExampleWorkflow.ts
import { DBOS } from '@dbos-inc/dbos-sdk'

async function exampleWorkflow(task: MyTask): Promise<MyResult> {
  // âœ… Allowed: DBOS methods at workflow level
  await DBOS.send('other-workflow', 'hello', 'TOPIC')
  const msg = await DBOS.recv<string>('TOPIC', 60)
  await DBOS.writeStream('logs', 'workflow started')

  // âœ… Allowed: Run steps
  const result = await DBOS.runStep(() => myStep(task.data), {
    name: 'myStep'
  })

  // âœ… Allowed: Start child workflows
  await DBOS.startWorkflow(childWorkflow, {
    workflowID: result.childId
  })(result.childData)

  return result
}

export const exampleWorkflow = DBOS.registerWorkflow(exampleWorkflow)
```

### Example Step

```typescript
// steps/ExampleStep.ts
async function myStep(data: string): Promise<StepResult> {
  // âœ… Allowed: Regular async operations
  const result = await database.query(...)
  await fetch('https://api.example.com')

  // âœ… Allowed: Stream data
  await DBOS.writeStream('progress', { percent: 50 })

  // âŒ NOT Allowed: DBOS context methods
  // await DBOS.send(...)       // Error!
  // await DBOS.recv(...)       // Error!
  // await DBOS.startWorkflow(...) // Error!

  return { result, childData: [...] }
}
```

---

**Maintainers**: BadLabs Engineering Team
**Contact**: [GitHub Issues](https://github.com/badaitech/chaingraph/issues)
**License**: Business Source License 1.1
