# Database Configuration
DATABASE_URL=postgres://postgres@0.0.0.0:5432/postgres?sslmode=disable
DATABASE_URL_EXECUTIONS=postgres://postgres@0.0.0.0:5432/postgres?sslmode=disable

# Kafka Configuration
KAFKA_BROKERS=localhost:9092,localhost:9093,localhost:9094
KAFKA_CLIENT_ID=chaingraph-executor
KAFKA_GROUP_ID_WORKER=chaingraph-execution-workers
KAFKA_GROUP_ID_STREAM=chaingraph-event-stream

# Worker Configuration
WORKER_ID=worker-default
WORKER_CONCURRENCY=10
WORKER_MEMORY_LIMIT_MB=512
WORKER_TIMEOUT_MS=300000

# Event Stream Configuration
EVENT_STREAM_PORT=3001
EVENT_STREAM_WS_PATH=/ws
EVENT_STREAM_BUFFER_SIZE=1000

# Logging Configuration
LOG_LEVEL=info
NODE_ENV=development

# Metrics Configuration
# Enable/disable metrics collection
ENABLE_METRICS=false

# Metrics log level (debug, info, warn)
METRICS_LOG_LEVEL=debug

# Sampling configuration - useful for high-throughput production environments
# Enable sampling to reduce log volume
METRICS_SAMPLING_ENABLED=false
# Sampling rate (0.0 to 1.0) - e.g., 0.1 means 10% of metrics are logged
METRICS_SAMPLING_RATE=1.0

# Batching configuration - batch metrics before logging to reduce I/O
# Number of metrics to batch before logging (1 = immediate logging)
METRICS_BATCH_SIZE=1
# Interval in ms to flush batched metrics
METRICS_FLUSH_INTERVAL=1000

# Include memory usage snapshots in metrics
METRICS_INCLUDE_MEMORY=false